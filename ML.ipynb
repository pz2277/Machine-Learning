{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7309635e",
   "metadata": {},
   "source": [
    "## Midterm Exam - Peizhi Zhang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e150f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aee3c0",
   "metadata": {},
   "source": [
    "### Use the spam dataset and variable descriptions in the files/Mid-Term Exam folder of the course website to answer the following questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bf3af0",
   "metadata": {},
   "source": [
    "### 1.  Import the spam dataset and print the first six rows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e31d147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make:</th>\n",
       "      <th>word_freq_address:</th>\n",
       "      <th>word_freq_all:</th>\n",
       "      <th>word_freq_3d:</th>\n",
       "      <th>word_freq_our:</th>\n",
       "      <th>word_freq_over:</th>\n",
       "      <th>word_freq_remove:</th>\n",
       "      <th>word_freq_internet:</th>\n",
       "      <th>word_freq_order:</th>\n",
       "      <th>word_freq_mail:</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;:</th>\n",
       "      <th>char_freq_(:</th>\n",
       "      <th>char_freq_[:</th>\n",
       "      <th>char_freq_!:</th>\n",
       "      <th>char_freq_$:</th>\n",
       "      <th>char_freq_#:</th>\n",
       "      <th>capital_run_length_average:</th>\n",
       "      <th>capital_run_length_longest:</th>\n",
       "      <th>capital_run_length_total:</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make:  word_freq_address:  word_freq_all:  word_freq_3d:  \\\n",
       "0             0.00                0.64            0.64            0.0   \n",
       "1             0.21                0.28            0.50            0.0   \n",
       "2             0.06                0.00            0.71            0.0   \n",
       "3             0.00                0.00            0.00            0.0   \n",
       "4             0.00                0.00            0.00            0.0   \n",
       "5             0.00                0.00            0.00            0.0   \n",
       "\n",
       "   word_freq_our:  word_freq_over:  word_freq_remove:  word_freq_internet:  \\\n",
       "0            0.32             0.00               0.00                 0.00   \n",
       "1            0.14             0.28               0.21                 0.07   \n",
       "2            1.23             0.19               0.19                 0.12   \n",
       "3            0.63             0.00               0.31                 0.63   \n",
       "4            0.63             0.00               0.31                 0.63   \n",
       "5            1.85             0.00               0.00                 1.85   \n",
       "\n",
       "   word_freq_order:  word_freq_mail:  ...  char_freq_;:  char_freq_(:  \\\n",
       "0              0.00             0.00  ...          0.00         0.000   \n",
       "1              0.00             0.94  ...          0.00         0.132   \n",
       "2              0.64             0.25  ...          0.01         0.143   \n",
       "3              0.31             0.63  ...          0.00         0.137   \n",
       "4              0.31             0.63  ...          0.00         0.135   \n",
       "5              0.00             0.00  ...          0.00         0.223   \n",
       "\n",
       "   char_freq_[:  char_freq_!:  char_freq_$:  char_freq_#:  \\\n",
       "0           0.0         0.778         0.000         0.000   \n",
       "1           0.0         0.372         0.180         0.048   \n",
       "2           0.0         0.276         0.184         0.010   \n",
       "3           0.0         0.137         0.000         0.000   \n",
       "4           0.0         0.135         0.000         0.000   \n",
       "5           0.0         0.000         0.000         0.000   \n",
       "\n",
       "   capital_run_length_average:  capital_run_length_longest:  \\\n",
       "0                        3.756                           61   \n",
       "1                        5.114                          101   \n",
       "2                        9.821                          485   \n",
       "3                        3.537                           40   \n",
       "4                        3.537                           40   \n",
       "5                        3.000                           15   \n",
       "\n",
       "   capital_run_length_total:  spam  \n",
       "0                        278     1  \n",
       "1                       1028     1  \n",
       "2                       2259     1  \n",
       "3                        191     1  \n",
       "4                        191     1  \n",
       "5                         54     1  \n",
       "\n",
       "[6 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/peizhi/Documents/Machine learning/spam_dataset.csv\")\n",
    "df.head(n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6daa16d",
   "metadata": {},
   "source": [
    "### 2.  Read through the documentation of the original dataset here:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names\n",
    "\n",
    "The dependent variable is \"spam\" where one indicates that an email is spam and zero otherwise.  Which three variables in the dataset do you think will be important predictors in a model of spam?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9255c1f",
   "metadata": {},
   "source": [
    "I believe that \"char_freq_#:\",\"word_freq_hp\", and \"word_freq_meeting\" are three variables in the dataset that will be important predictors. First, in the non-spam emails, people rarely write hashtag (#) to send a message to colleague or someone that is close to them; mostly in the spam emails, there will be hashtags to promote something or display as an ad slogan. Second, in the csv file, the word \"hp\" rarely appears in the first 1814 rows, which are the rows for spam = 1, while in the following rows that indicate non-spam emails, the percentage are much higher overall. Third, \"meeting\" is a word usually used in a professional setting, which will be a good indicator of non-spam letters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e040a699",
   "metadata": {},
   "source": [
    "### 3.  Visualize the univariate distribution of each of the variables in the previous question.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59fdc565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dependent Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df['spam'].value_counts().plot.bar()\n",
    "plt.xlabel('Non-spam                                Spam')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b741a658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'frequency of hashtag occurance in emails')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Independent Variables\n",
    "df['char_freq_#:'].plot(kind='density')\n",
    "plt.xlabel('frequency of hashtag occurance in emails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "420f333c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'frequency of the word \"hp\" in emails')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['word_freq_hp:'].plot(kind='density')\n",
    "plt.xlabel('frequency of the word \"hp\" in emails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01a2a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'frequency of the word \"meeting\" in emails')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['word_freq_meeting:'].plot(kind='density')\n",
    "plt.xlabel('frequency of the word \"meeting\" in emails')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd503c",
   "metadata": {},
   "source": [
    "### 4. Name each of the supervised learning models that we have learned thus far that are used to predict dependent variables like \"spam\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aec9c6",
   "metadata": {},
   "source": [
    "Since \"spam\" is a categorical variable in a categorical model, the supervised learning models that can be used to predict \"spam\" are logistic regression, k nearest neighbor for classification model, decision tree, support vector machines, and penalized logistic regression (in which \"penalty = none\" is Lasso regression and \"penalty does not equal to none\" is Ridge regression). \n",
    "\n",
    "A logistic regression model can be used to predict a binary outcome or categorical dependent variable with code as 1 (=yes), and 0 (=no), by plotting the depedent variable's probability scores. We can use fitted logistic regression model to predict if an email is spam or non-spam by predicting the class membership probabilities of the new observations. \n",
    "\n",
    "A penalized logistic regression can predict categorical outcomes the same way as logistic regression models, but with additional constraints to the model. By adding a lamda/alpha, it constrains the size of the coefficients, in order to have a shrinking effect on the variables that do not contribute to the prediction task.\n",
    "\n",
    "A classification model with k nearest neighbor parameter can predict if an email is spam or non-spam by defining k value and calculating the new observation's similarity to \"spam\" using distance measurement. \n",
    "\n",
    "A support vector machine is used for predicting categorical variables by mapping the independent variables to dependent variable, in which the decision boundary separates different classes. \n",
    "\n",
    "A decision tree uses tree-structured classifier to represent the data set and the decision rules. It is able to predict categorical variable \"spam\" by calculating the average of the value of being \"spam\" in a specific leaf node. With iterations, it can predict a final value for the new independent data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c4425",
   "metadata": {},
   "source": [
    "### 5. Describe the importance of training and test data.  Why do we separate data into these subsets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b180a",
   "metadata": {},
   "source": [
    "In a supervised learning model, we split data into training data and test data with random test split. This process will produce four outputs, including X_train, y_train, X_test, y_test. Setting up data objects into training and test data subsets is important because we can have, for example, 75% of training data used for fitting the model/training the algorithm, and 25% of test data can be held out to predict on X_test data and evaluate on y_test data using the fitted model, so that we can eventually evaluate how well the model can perform on unseen data. In other words, we use training data to generate machine learning models with attributes such as Euclidean distance; we then score on the test data using the fitted model to generate predictions on new data. We care about the accuracy of test_scores the most because we want to predict the unseen data, not the train_score. There could be instances where overfitting models exist, as we are focusing only on the training data, and having better predictive power on the training data, but at some point, we will lose the signal of the held out information (test data). To predict well across all observations, we need both training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ef165",
   "metadata": {},
   "source": [
    "### 6. What is k-fold cross validation and what do we use it for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c57aac6",
   "metadata": {},
   "source": [
    "K-fold cross validation is a better method to evaluate a model than the simple train_test_split because in k-fold cross validation, through iteration of fitting the model with different data, the average of metrics offers a better benchmark for the performance for the model. In addition, we could encounter issues of overfitting models and underfitting models when we are focusing too much on the training model or fitting on the test data. In order to have maximum amount of training data to fit the model as well as maximum amount of test data for scoring the unseen data, we use k-fold cross validation. With K-fold CV, there is no repeated observations, but a repeated process of train_test_split with maximum amount of data to train on and test on. \n",
    "\n",
    "K-fold cross validation is the default method that we use to validate the stability of the ML model, to see if the model is overfit or not based on the n metrics results and metrics' mean. First we use train_test_split method to have, for example, 80% of training data and 20% of held out test data. Then, we do the cross validation among the 80% of the training data. If k-fold (n_splits = 5), we split the training data into 5 folds, in which we train on 4 folds of the data, and then validate on 1 fold of the data. We get the evaluative metric (aka: accuracy in this case) on the validated data. Next, we repeat the same process on a different fold of data as validation data, while using the rest of 4 folds as training data. We get another accuracy metric from the model. Eventually, we average out the five evaluative metrics to get the robust metric. In a way, we are using all the data for training and testing, without repetition. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f4309a",
   "metadata": {},
   "source": [
    "### 7. How is k-fold cross validation different from stratified k-fold cross validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b977b2",
   "metadata": {},
   "source": [
    "Stratified k-fold cross validation makes sure the relative class frequencies in each fold are proportional to the relative class frequencies on the whole datasets. For instance, for k-fold cross validation, we split the training data into 3 folds; for stratified k-fold cross validation, we further break down into 3 subsets for each of the 3 folds. In this way, we can avoid the imbalance of classes for the dependent variables in the k-fold cross validation. \n",
    "\n",
    "In the stratified k-fold cross validation, we have leave-out-out CV and repeated k-fold CV. For repeated k-fold CV, we apply k-fold or stratified k-fold validation multiple times with shuffled data. That is to say, we split the training data into 5 folds and get the average metric from each validation data and training data. Then, we shuffle the data again to have 5 folds of different observations and get the new average metric. In this case, we can do 10 times/shuffles, to get the average of 50 accuracy metrics to avoid the issue of randomization that can still exists in cross validation. Because for the cross validation, we can still have a sample from test data that does not contribute to the prediction of the unseen data. With repeated k-fold cross validation, we can get even more robust metric than stratified k-fold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550713ad",
   "metadata": {},
   "source": [
    "### 8. Choose one model from question four.  Split the data into training and test subsets.  Build a model with the three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k).  Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55c8de44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   char_freq_#:  word_freq_hp:  word_freq_meeting:  spam\n",
      "0         0.000            0.0                 0.0     1\n",
      "1         0.048            0.0                 0.0     1\n",
      "2         0.010            0.0                 0.0     1\n",
      "3         0.000            0.0                 0.0     1\n",
      "4         0.000            0.0                 0.0     1\n"
     ]
    }
   ],
   "source": [
    "# select only three independent variables\n",
    "d = df [['char_freq_#:','word_freq_hp:','word_freq_meeting:','spam']].copy()\n",
    "print(d.head(n=5))\n",
    "\n",
    "#split data into training and test subsets\n",
    "y = d['spam']\n",
    "X = d.loc[:, d.columns !='spam']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "829d0a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#Scale the data for KNN Classifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f60998bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN for REGRESSION (GridSearchCV)\n",
      "Best Parameter: {'n_neighbors': 9}\n",
      "Best Cross-Validation Score: 0.675\n",
      "Test set Score: 0.665\n",
      "\n",
      "KNN CLASSIFER (SCALED DATA)\n",
      "Test set score: 0.665\n",
      "accuracy: 0.6646394439617723\n",
      "RepeatedKFold:\n",
      "0.664282271419592\n",
      "Mean Cross Validation, KFold: 0.675\n"
     ]
    }
   ],
   "source": [
    "# Scaled KNN for Classification Using K-fold Cross-Validation\n",
    "\n",
    "# GridSearchCV with KNN for Classification\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "knn_param_grid = {'n_neighbors': range(1, 10)}\n",
    "\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_param_grid).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"KNN for REGRESSION (GridSearchCV)\")\n",
    "print(\"Best Parameter: {}\".format(knn_grid.best_params_))\n",
    "print(\"Best Cross-Validation Score: {:.3f}\".format(knn_grid.best_score_))\n",
    "print(\"Test set Score: {:.3f}\".format(knn_grid.score(X_test_scaled, y_test)))\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print(\"\")\n",
    "print(\"KNN CLASSIFER (SCALED DATA)\")\n",
    "knn_scaled = KNeighborsClassifier(n_neighbors = 9).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate prediction error on test data directly \n",
    "\n",
    "print(\"Test set score: {:.3f}\".format(knn_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"accuracy: \"+str(knn_scaled.score(X_test_scaled, y_test)))\n",
    "y_pred = knn_scaled.predict(X_test_scaled) \n",
    "y_pred\n",
    "\n",
    "# Evaluate prediction error on k-fold CV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from statistics import mean \n",
    "\n",
    "kfold = KFold(n_splits=9)\n",
    "rkf = RepeatedKFold(n_splits=9, n_repeats=10)\n",
    "\n",
    "print(\"RepeatedKFold:\\n{}\".format(\n",
    "    mean(cross_val_score(knn_scaled, X_train, y_train, cv=rkf))))\n",
    "\n",
    "print(\"Mean Cross Validation, KFold: {:.3f}\".format(\n",
    "    np.mean(cross_val_score(knn_scaled, X_train_scaled, y_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f975a3e",
   "metadata": {},
   "source": [
    "I chose KNeighborsClassifier(n_neighbors=9) because odd numbers are better to break any ties in majority votes, and through tuning the model, the best parameter for this model is 9. However, the cross-validation score and the test set score are both low. The reason might be because the parameter is too high, which increases the complexity of running the model. When k is larger than 5, the model may become less efficient and slows down the prediction model. In this dataset of 4601 samples, smaller file size may predict more quickly, which is why I will use smaller parameter for the models below. \n",
    "\n",
    "After evaluating the model, it turns out that knn for classification model did not fit very well on the test data, and the mean accuracy metric is also low (=0.675). The reason for that might be due to the variables are not best at predicting spam emails. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a64f97",
   "metadata": {},
   "source": [
    "### 9. Choose a second model from question four.  Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k).  Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a34df33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION (GridSearchCV)\n",
      "Best Parameter: {'C': 0.001}\n",
      "Best Cross-Validation Score: 0.689\n",
      "Test set Score: 0.656\n",
      "\n",
      "LOGISTIC REGRESSION (UNSCALED DATA)\n",
      "Test set score: 0.656\n",
      "Accuracy: 0.6559513466550826\n",
      "Mean Cross Validation, KFold: 0.689\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_freq_#:</th>\n",
       "      <th>word_freq_hp:</th>\n",
       "      <th>word_freq_meeting:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression Coefficients</th>\n",
       "      <td>1.412689</td>\n",
       "      <td>-4.960798</td>\n",
       "      <td>-2.832322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  char_freq_#:  word_freq_hp:  \\\n",
       "Logistic Regression Coefficients      1.412689      -4.960798   \n",
       "\n",
       "                                  word_freq_meeting:  \n",
       "Logistic Regression Coefficients           -2.832322  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# GridSearch CV with Logistic Regression Model\n",
    "\n",
    "logreg_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "logreg_grid = GridSearchCV(LogisticRegression(penalty='none'), logreg_param_grid).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"LOGISTIC REGRESSION (GridSearchCV)\")\n",
    "print(\"Best Parameter: {}\".format(logreg_grid.best_params_))\n",
    "print(\"Best Cross-Validation Score: {:.3f}\".format(logreg_grid.best_score_))\n",
    "print(\"Test set Score: {:.3f}\".format(logreg_grid.score(X_test_scaled, y_test)))\n",
    "\n",
    "print('')\n",
    "print(\"LOGISTIC REGRESSION (UNSCALED DATA)\")\n",
    "\n",
    "logreg = LogisticRegression(C=0.001, penalty = 'none').fit(X_train_scaled, y_train)\n",
    "# Evaluate prediction error on test data directly\n",
    "\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_scaled, y_test)))\n",
    "y_pred2 = logreg.predict(X_test_scaled)\n",
    "print(\"Accuracy:\",logreg.score(X_test_scaled, y_test))\n",
    "\n",
    "# Evaluate prediction error on k-fold CV\n",
    "\n",
    "print(\"Mean Cross Validation, KFold: {:.3f}\".format(np.mean(cross_val_score(logreg, X_train_scaled, y_train))))\n",
    "\n",
    "# Model coefficients\n",
    "logreg_coef = pd.DataFrame(data=logreg.coef_, columns=X.columns, index=['Logistic Regression Coefficients'])\n",
    "logreg_coef.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb450ef",
   "metadata": {},
   "source": [
    "In the logistic regression model, I chose C=0.001 for the parameter because through tuning the model, the best parameter is 0.001. A small \"C\" parameter suggests stronger regularization strength of the model, so that the model is better at predicting the unseen data. As it is displayed from the kfold value, which is 0.689 and higher than the previous model.  \n",
    "\n",
    "The test score is the same as KNN model for classification. The k fold cross validation (=0.689) is higher than the one from previous model, which means that the accuracy metrics' average is higher for logistic regression model. Overall, this second model predict a little better than the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee49f78",
   "metadata": {},
   "source": [
    "### 10. Choose a third model from question four.  Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k). Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0430778f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENLIZED LOGISTIC REGRESSION - L1 (SCALED DATA)\n",
      "Best Parameter: {'C': 10}\n",
      "Best Cross-Validation Score: 0.689\n",
      "Test set Score: 0.656\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV with L1 Penalized Logistic Regression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pen_logreg_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "pen_logreg_grid_l1 = GridSearchCV(LogisticRegression(penalty='l1', solver = 'liblinear'), \n",
    "                                  pen_logreg_param_grid).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"PENLIZED LOGISTIC REGRESSION - L1 (SCALED DATA)\")\n",
    "print(\"Best Parameter: {}\".format(pen_logreg_grid_l1.best_params_))\n",
    "print(\"Best Cross-Validation Score: {:.3f}\".format(pen_logreg_grid_l1.best_score_))\n",
    "print(\"Test set Score: {:.3f}\".format(pen_logreg_grid_l1.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99f4c71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENALIZED LOGISTIC REGRESSION - L1 (SCALED DATA)\n",
      "Test set score: 0.656\n",
      "Accuracy: 0.6559513466550826\n",
      "Mean Cross Validation, KFold: 0.689\n"
     ]
    }
   ],
   "source": [
    "# L1 Penalized Logistic Regression Model (Lasso)\n",
    "pen_logreg_scaled_l1 = LogisticRegression(C=10, penalty = 'l1', \n",
    "                                          solver = 'liblinear').fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"PENALIZED LOGISTIC REGRESSION - L1 (SCALED DATA)\")\n",
    "\n",
    "# Evaluate prediction error on test data directly\n",
    "\n",
    "print(\"Test set score: {:.3f}\".\n",
    "      format(pen_logreg_scaled_l1.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(\"Accuracy:\",pen_logreg_scaled_l1.score(X_test_scaled, y_test))\n",
    "\n",
    "# Stratified Kfold Cross Validation \n",
    "print(\"Mean Cross Validation, KFold: {:.3f}\".format(\n",
    "    np.mean(cross_val_score(pen_logreg_scaled_l1, X_train_scaled, y_train))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f74fea",
   "metadata": {},
   "source": [
    "The parameter I chose for L1 penalized logistic regression is C = 10 because of the best parameter from GridSearchCV, with a less strong regularization strength than the previous model. \n",
    "\n",
    "With a less strong regularization on the model, the Lasso model did not improve as the test score and kfold score is still the same. The model still did not predict better because the independent variables I used might not be the most ideal, and could not predict spam very well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28c8d9",
   "metadata": {},
   "source": [
    "### 11. Choose a fourth model from question four.  Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k). Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation. Evaluate prediction error, did this model predict better than your previous models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76aab421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENLIZED LOGISTIC REGRESSION - L2 (GridSearchCV)\n",
      "Best Parameter: {'C': 100}\n",
      "Best Cross-Validation Score: 0.689\n",
      "Test set Score: 0.656\n",
      "PENALIZED LOGISTIC REGRESSION - L2 (SCALED DATA)\n",
      "Test set score: 0.656\n",
      "Mean Cross Validation, KFold: 0.689\n"
     ]
    }
   ],
   "source": [
    "#GridSearchCV with L2 Penalized Logistic Regression\n",
    "\n",
    "pen_logreg_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "pen_logreg_grid_l2 = GridSearchCV(LogisticRegression(), pen_logreg_param_grid).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"PENLIZED LOGISTIC REGRESSION - L2 (GridSearchCV)\")\n",
    "print(\"Best Parameter: {}\".format(pen_logreg_grid_l2.best_params_))\n",
    "print(\"Best Cross-Validation Score: {:.3f}\".format(pen_logreg_grid_l2.best_score_))\n",
    "print(\"Test set Score: {:.3f}\".format(pen_logreg_grid_l2.score(X_test_scaled, y_test)))\n",
    "\n",
    "# L2 Penalized Logistic Regression Model (Ridge)\n",
    "\n",
    "pen_logreg_scaled_l2 = LogisticRegression(C = 100, penalty = 'l2').fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"PENALIZED LOGISTIC REGRESSION - L2 (SCALED DATA)\")\n",
    "\n",
    "# Evaluate prediction error on test data directly\n",
    "print(\"Test set score: {:.3f}\".format(pen_logreg_scaled_l2.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Kfold Cross Validation \n",
    "print(\"Mean Cross Validation, KFold: {:.3f}\".format(np.mean(cross_val_score(pen_logreg_scaled_l2, X_train_scaled, y_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ba5584",
   "metadata": {},
   "source": [
    "The parameter I chose for this model is C=100, based on the tuned parameter from GridSearchCV. The penalty strength for the Ridge model has become even less stronger than all the previous models, which further influences the constraint we set on the coefficients. This model with a high parameter might not be able to get rid of the coefficients that least predict the unseen data.\n",
    "\n",
    "The k-fold value is the same for logistic regression and penalized logistic regression models, which is 0.689 and also the highest of all four models. Even though the test score has not improved, the three logistic regression models might be better prediction models than KNN for classification model in question 8. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3eb6e7",
   "metadata": {},
   "source": [
    "### 12. Now rerun your best model from questions 8 through 11, but this time add three new variables to the model that you think will increase prediction accuracy.   Did this model predict test data better than your previous models? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "786a71ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   char_freq_#:  word_freq_hp:  word_freq_meeting:  word_freq_george:  \\\n",
      "0         0.000            0.0                 0.0                0.0   \n",
      "1         0.048            0.0                 0.0                0.0   \n",
      "2         0.010            0.0                 0.0                0.0   \n",
      "3         0.000            0.0                 0.0                0.0   \n",
      "4         0.000            0.0                 0.0                0.0   \n",
      "\n",
      "   capital_run_length_average:  word_freq_650:  spam  \n",
      "0                        3.756             0.0     1  \n",
      "1                        5.114             0.0     1  \n",
      "2                        9.821             0.0     1  \n",
      "3                        3.537             0.0     1  \n",
      "4                        3.537             0.0     1  \n"
     ]
    }
   ],
   "source": [
    "# select six independent variables\n",
    "d2 = df [[\n",
    "    'char_freq_#:','word_freq_hp:','word_freq_meeting:','word_freq_george:',\n",
    "    'capital_run_length_average:','word_freq_650:','spam']].copy()\n",
    "\n",
    "print(d2.head(n=5))\n",
    "\n",
    "#split data into training and test subsets\n",
    "y2 = d2['spam']\n",
    "X2 = d2.loc[:, d2.columns !='spam']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size= 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f41bf470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 Penalized Logistic Regression Model (Lasso)\n",
    "\n",
    "# Scale the data \n",
    "\n",
    "scaler2 = StandardScaler().fit(X2_train)\n",
    "X2_train_scaled = scaler2.transform(X2_train)\n",
    "X2_test_scaled = scaler2.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "feb6ffcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENLIZED LOGISTIC REGRESSION - L1 (SCALED DATA)\n",
      "Best Parameter: {'C': 10}\n",
      "Best Cross-Validation Score: 0.832\n",
      "Test set Score: 0.818\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV with L1 Penalized Logistic Regression\n",
    "\n",
    "pen_logreg_param_grid2 = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "pen_logreg_grid_l1_2 = GridSearchCV(LogisticRegression(penalty='l1', solver = 'liblinear'), \n",
    "                                  pen_logreg_param_grid2).fit(X2_train_scaled, y2_train)\n",
    "\n",
    "print(\"PENLIZED LOGISTIC REGRESSION - L1 (SCALED DATA)\")\n",
    "print(\"Best Parameter: {}\".format(pen_logreg_grid_l1_2.best_params_))\n",
    "print(\"Best Cross-Validation Score: {:.3f}\".format(pen_logreg_grid_l1_2.best_score_))\n",
    "print(\"Test set Score: {:.3f}\".format(pen_logreg_grid_l1_2.score(X2_test_scaled, y2_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a09af766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENALIZED LOGISTIC REGRESSION - L1 (SCALED DATA)\n",
      "Test set score: 0.818\n",
      "Mean Cross Validation, KFold: 0.832\n"
     ]
    }
   ],
   "source": [
    "# Running and Evaluating the L1 Penalized Logistic Regression Model \n",
    "\n",
    "pen_logreg_l1 = LogisticRegression(C=10, penalty = 'l1', \n",
    "                                          solver = 'liblinear').fit(X2_train_scaled, y2_train)\n",
    "\n",
    "# Evaluate prediction error on test data directly\n",
    "\n",
    "print(\"PENALIZED LOGISTIC REGRESSION - L1 (SCALED DATA)\")\n",
    "\n",
    "print(\"Test set score: {:.3f}\".\n",
    "      format(pen_logreg_l1.score(X2_test_scaled, y2_test)))\n",
    "\n",
    "# Repeated Kfold Cross Validation \n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "print(\"Mean Cross Validation, KFold: {:.3f}\".format(np.mean(cross_val_score(\n",
    "    pen_logreg_l1, X2_train, y2_train, cv=rkf))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5559f06",
   "metadata": {},
   "source": [
    "The new logistic regression model with penalty 1 predicts much better than the previous models with only three independent variables. The test set scores for the previous models are around 0.656, while the test score for the new model with six independent variables is 0.818. The repeated kfold score is also much higher, with a value of 0.832, which means that the average score for accuracy metrics is 0.832. \n",
    "\n",
    "The reason for better prediction and model evaluation is because the new variables can predict \"spam\" emails better in addition to the existing variables. For instance, 'capital_run_length_average:' indicates the average length of uninterrupted sequence of capital letters. In spam emails, there is a higher chance of an entire email with capital letters, in contrast to work and personal emails that have more regularized spelling and format. The higher word frequencies of 'George' and '650' are indicators of non-spam emails, as suggested in the data description. In addition, the Lasso regression model adds a restriction to variables with lamda, so that we can control which variables are better at predicting the model and which variables are not. The logistic regression with L1 penalty adds a new dimension to tuning the parameter in addition to using GridSearchCV. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665ac12",
   "metadata": {},
   "source": [
    "### 13. Rerun all your other models with this final set of six variables, evaluate prediction error, and choose a final model.  Why did you select this model among all of the models that you ran?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d4613d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN for REGRESSION (SCALED DATA)\n",
      "Best Parameter: {'n_neighbors': 5}\n",
      "Best Cross-Validation Score: 0.832\n",
      "Test set Score: 0.830\n"
     ]
    }
   ],
   "source": [
    "# Model 2: K Nearest Neighbor for Classification Model \n",
    "\n",
    "# GridSearchCV with KNN for Classification \n",
    "\n",
    "knn_param_grid2 = {'n_neighbors': range(1, 10)}\n",
    "\n",
    "knn_grid2 = GridSearchCV(KNeighborsClassifier(), knn_param_grid2).fit(X2_train_scaled, y2_train)\n",
    "\n",
    "print(\"KNN for REGRESSION (SCALED DATA)\")\n",
    "print(\"Best Parameter: {}\".format(knn_grid2.best_params_))\n",
    "print(\"Best Cross-Validation Score: {:.3f}\".format(knn_grid2.best_score_))\n",
    "print(\"Test set Score: {:.3f}\".format(knn_grid2.score(X2_test_scaled, y2_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "397d44a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLASSIFER (SCALED DATA)\n",
      "Test set score: 0.830\n",
      "accuracy: 0.8297132927888793\n",
      "RepeatedKFold:\n",
      "0.8270434782608695\n"
     ]
    }
   ],
   "source": [
    "knn_scaled2 = KNeighborsClassifier(n_neighbors = 5).fit(X2_train_scaled, y2_train)\n",
    "\n",
    "# Evaluate prediction error on test data directly\n",
    "print(\"KNN CLASSIFER (SCALED DATA)\")\n",
    "\n",
    "print(\"Test set score: {:.3f}\".format(knn_scaled2.score(X2_test_scaled, y2_test)))\n",
    "print(\"accuracy: \"+str(knn_scaled2.score(X2_test_scaled, y2_test)))\n",
    "y_pred2 = knn_scaled2.predict(X2_test) \n",
    "y_pred2\n",
    "\n",
    "# Evaluate prediction error on k-fold CV\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "print(\"RepeatedKFold:\\n{}\".format(\n",
    "    mean(cross_val_score(knn_scaled2, X2_train, y2_train, cv=rkf))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bb5f531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION (SCALED DATA)\n",
      "Best Parameter: {'C': 0.001}\n",
      "Best Cross-Validation Score: 0.830\n",
      "Test set Score: 0.819\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Logistic Regression Model\n",
    "\n",
    "# GridSearchCV with Logistic Regression Model\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "logreg_param_grid2 = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "logreg_grid3 = GridSearchCV(LogisticRegression(penalty='none'), logreg_param_grid2).fit(X2_train_scaled, y2_train)\n",
    "\n",
    "print(\"LOGISTIC REGRESSION (SCALED DATA)\")\n",
    "print(\"Best Parameter: {}\".format(logreg_grid3.best_params_))\n",
    "print(\"Best Cross-Validation Score: {:.3f}\".format(logreg_grid3.best_score_))\n",
    "print(\"Test set Score: {:.3f}\".format(logreg_grid3.score(X2_test_scaled, y2_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63032f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION (SCALED DATA)\n",
      "Test set score: 0.819\n",
      "Mean Cross Validation, KFold: 0.831\n"
     ]
    }
   ],
   "source": [
    "logreg_scaled2 = LogisticRegression(C=0.001, penalty='none').fit(X2_train_scaled, y2_train)\n",
    "\n",
    "# Evaluate prediction error on test data directly\n",
    "print(\"LOGISTIC REGRESSION (SCALED DATA)\")\n",
    "print(\"Test set score: {:.3f}\".format(logreg_scaled2.score(X2_test_scaled, y2_test)))\n",
    "\n",
    "# Evaluate prediction error on kfold cross validation\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "print(\"Mean Cross Validation, KFold: {:.3f}\".format(np.mean(cross_val_score(logreg_scaled2, X2_train_scaled,\n",
    "                                                                            y2_train, cv=rkf))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a787602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENLIZED LOGISTIC REGRESSION - L2 (SCALED DATA)\n",
      "Best Parameter: {'C': 100}\n",
      "Best Cross-Validation Score: 0.832\n",
      "Test set Score: 0.819\n"
     ]
    }
   ],
   "source": [
    "# Model 4: L2 Penalized Logistic Regression Model (Ridge)\n",
    "\n",
    "# GridSearchCV with L2 Penalized Logistic Regression\n",
    "\n",
    "pen_logreg_param_grid2 = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "pen_logreg_grid_l2_2 = GridSearchCV(LogisticRegression(), pen_logreg_param_grid2).fit(X2_train_scaled, y2_train)\n",
    "\n",
    "print(\"PENLIZED LOGISTIC REGRESSION - L2 (SCALED DATA)\")\n",
    "print(\"Best Parameter: {}\".format(pen_logreg_grid_l2_2.best_params_))\n",
    "print(\"Best Cross-Validation Score: {:.3f}\".format(pen_logreg_grid_l2_2.best_score_))\n",
    "print(\"Test set Score: {:.3f}\".format(pen_logreg_grid_l2_2.score(X2_test_scaled, y2_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3105b1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENALIZED LOGISTIC REGRESSION - L2 (SCALED DATA)\n",
      "Test set score: 0.819\n",
      "Mean Cross Validation, KFold: 0.834\n"
     ]
    }
   ],
   "source": [
    "pen_logreg_l2 = LogisticRegression(C=100, penalty='l2', solver = 'liblinear').fit(X2_train, y2_train) \n",
    "\n",
    "# Evaluate prediction error on test data directly\n",
    "\n",
    "print(\"PENALIZED LOGISTIC REGRESSION - L2 (SCALED DATA)\")\n",
    "print(\"Test set score: {:.3f}\".format(pen_logreg_l2.score(X2_test, y2_test)))\n",
    "\n",
    "# Repeated Kfold Cross Validation \n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "print(\"Mean Cross Validation, KFold: {:.3f}\".format(np.mean(cross_val_score(\n",
    "    pen_logreg_l2, X2_train, y2_train, cv=rkf))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf4dca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENALIZED LOGISTIC REGRESSION - L1\n",
      "Scaled: 0.818\n",
      "Mean Cross Validation, KFold: 0.833\n",
      "\n",
      "LOGISTIC REGRESSION\n",
      "Scaled: 0.819\n",
      "Mean Cross Validation, KFold: 0.831\n",
      "\n",
      "PENALIZED LOGISTIC REGRESSION - L2\n",
      "Test set score: 0.819\n",
      "Mean Cross Validation, KFold: 0.834\n",
      "\n",
      "KNN CLASSIFIER\n",
      "Scaled: 0.830\n",
      "RepeatedKFold:\n",
      "0.828463768115942\n"
     ]
    }
   ],
   "source": [
    "# Choosing the final model\n",
    "\n",
    "print(\"PENALIZED LOGISTIC REGRESSION - L1\")\n",
    "print(\"Scaled: {:.3f}\".format(pen_logreg_l1.score(X2_test_scaled, y2_test)))\n",
    "print(\"Mean Cross Validation, KFold: {:.3f}\".format(np.mean(cross_val_score(pen_logreg_l1, X2_train, y2_train, cv=rkf))))\n",
    "print(\"\")\n",
    "print(\"LOGISTIC REGRESSION\")\n",
    "print(\"Scaled: {:.3f}\".format(logreg_scaled2.score(X2_test_scaled, y2_test)))\n",
    "print(\"Mean Cross Validation, KFold: {:.3f}\".format(np.mean(cross_val_score(logreg_scaled2, X2_train_scaled,\n",
    "                                                                            y2_train, cv=rkf))))\n",
    "print(\"\")\n",
    "print(\"PENALIZED LOGISTIC REGRESSION - L2\")\n",
    "print(\"Test set score: {:.3f}\".format(pen_logreg_l2.score(X2_test, y2_test)))\n",
    "print(\"Mean Cross Validation, KFold: {:.3f}\".format(np.mean(cross_val_score(pen_logreg_l2, X2_train, y2_train, cv=rkf))))\n",
    "print(\"\")\n",
    "print(\"KNN CLASSIFIER\")\n",
    "print(\"Scaled: {:.3f}\".format(knn_scaled2.score(X2_test_scaled, y2_test)))\n",
    "print(\"RepeatedKFold:\\n{}\".format(\n",
    "    mean(cross_val_score(knn_scaled2, X2_train, y2_train, cv=rkf))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41fa79c",
   "metadata": {},
   "source": [
    "The final model I choose is the L2 Penalized Logistic Regression model with 6 independent variables because it has the highest average score for accuracy metric, which is kfold = 0.834. I chose the model with additional independent variables because the new variables predict better, in contrast to the models from Q8 - Q11. Although the test scores and k-fold scores are similar among the above four models, which are all around 0.80 ~ 0.85, cross validation score is a better evaluation metric since we get an average accuracy score from 5 fitted models with the maximum usage of both testing and training data. \n",
    "\n",
    "Furthermore, the L2 penalized logistic regression model is able to constrain the size of the coefficients and reduce the coefficients that least predict the unseen data. In this L2 penalized logistic regression model, the best parameter is C=100, meaning that the higher the inverse of regularization strength, the lower the penalization of the model. Even with a lower value of constraint to the coefficients, as compared to L1 penalized logistic regression (the best parameter is C=10), L2 penalized logistic regression still has a higher accuracy metric. That is why I chose L2 penalized logistic regression, as it maximizes the accuracy of the fitted model on predicting on the unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2374b71",
   "metadata": {},
   "source": [
    "### 14. What variable that currently is not in your model, if included, would be likely to increase your final model's predictive power?  For this answer try to speculate about a variable outside the variables available in the data that would improve you model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d594d2",
   "metadata": {},
   "source": [
    "The variable that might increase my final model's predictive power is 'freq_word_code:' because many spam emails suggest to use 'code' for certain products and the frequency of this word in spam emails is extremely high. On the other hand, even with data-related tasks or jobs, the work emails do not usually mention 'code' but rather more general terms such as 'project'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea6839f",
   "metadata": {},
   "source": [
    "### 15. Lastly, you have listed each of the models that we have learned to use to predict dependent variables like spam.  List each model we have focused on in class thus far that you could use to evaluate data with a continuous dependent variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb844934",
   "metadata": {},
   "source": [
    "For evaluating data with a continuous dependent variable, we can use k nearest neighbor for regression model, linear regression model, ridge regression model, and lasso regression model. \n",
    "\n",
    "A regression model with k nearest regressor uses 'feature similarity' to predict new observations. The new data points are assigned a value based on how similarly they are to the points in the training set.\n",
    "\n",
    "A linear regression model predicts new data points by measuring the residual sum of squares (RSS), which is the difference between population data and sample data.\n",
    "\n",
    "A ridge or lasso regression model predicts new data points in the same way as linear regression, with additional constraints to beta, so that only the variables that contribute to prediction tasks are included. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
